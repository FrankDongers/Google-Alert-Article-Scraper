#Author: Frank Dong
#Date: Dec 15 2019
#Purpose: Link grabber for PDFs generated by Google Alerts

import PyPDF2
import os
import requests

class Null:
    def __init__(self, *args, **kwargs): pass
    def __call__(self, *args, **kwargs): return self
    def __repr__(self): return "Null()"
    def setLink(self, link): return self
    def setDate(self,link): return self
    def getLink(self): return self
    def getDate(self): return self

class LinkEntry:
	def __init__(self):
	    self.link = ""
	    self.date = ""

	def setLink(self, link):
		self.link = link

	def setDate(self, date):
		self.date = date

	def getLink(self):
		return str(self.link)

	def getDate(self):
		return str(self.date)


p1 = Null()
p1.setDate("Jan")
p1.setLink("Moo")
print (p1.getLink())



try:
	os.remove("links.txt")
except:
	pass

rawList = []
places = []
f = open("links.txt", "a")
#readArray = ["2018.09.pdf", "2018.10.pdf","2018.11.pdf","2018.12.pdf","2019.01.pdf","2019.02.pdf","2019.03.pdf","2019.04.pdf","2019.05.pdf","2019.06.pdf","2019.07.pdf","2019.08.pdf","2019.09.pdf","2019.10.pdf","2019.11.pdf"]
readArray = ["2018.09.pdf"]
arrayCount = 0

for i in range(len(readArray)):
	PDFFile = open("pdfs/" + readArray[i],'rb')
	PDF = PyPDF2.PdfFileReader(PDFFile)
	pages = PDF.getNumPages()
	key = '/Annots'
	uri = '/URI'
	ank = '/A'

	for page in range(pages):
		print (arrayCount)
		print("Processing Page: {}".format(page))
		pageSliced = PDF.getPage(page)
		pageObject = pageSliced.getObject()
		if key in pageObject.keys():
			ann = pageObject[key]
			for a in ann:
				objLink = LinkEntry()
				u = a.getObject()
				if uri in u[ank].keys():
					if str(u[ank][uri]).startswith('https://www.google.com/url?'):
						#print("\n", str(u[ank][uri]).replace("https://www.google.com/url?rct=j&sa=t&url=", "").split("&ct",1)[0])
						objLink.setLink(str(u[ank][uri]).replace("https://www.google.com/url?rct=j&sa=t&url=", "").split("&ct",1)[0])
						objLink.setDate(readArray[arrayCount].replace(".pdf",""))
						rawList.append(objLink)
						#f.write(str(u[ank][uri]).replace("https://www.google.com/url?rct=j&sa=t&url=", "").split("&ct",1)[0] + "\n")
	arrayCount = arrayCount + 1

print ("PDF Successfully Parsed")

for x in rawList:
	print ("Testing Connection To:" + x.getLink())
	places.append(x)
	try:
		requests.get(x.getLink(), timeout=10)  # wait up to 10 seconds
	except requests.exceptions.Timeout:
		print ("Timed Out")
		nullLink = Null()
		places.pop()
		places.append(nullLink)
		pass  # handle the timeout
	except:
		print ("Error in Link")
		nullLink = Null()
		places.pop()
		places.append(nullLink)
		pass

count = 1
for i in places:
	if not isinstance(i, Null):
		f.write(i.getLink() + "," + i.getDate() + "\n")
		count = count + 1

f.close()




